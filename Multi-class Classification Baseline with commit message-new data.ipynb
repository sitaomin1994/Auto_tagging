{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# funtions to handle labels\n",
    "from utils.handle_labels import get_tag_counts_and_labels\n",
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from utils.handle_labels import categories_count\n",
    "from utils.handle_labels import get_imbalance\n",
    "from utils.handle_labels import label_distribution\n",
    "from utils.handle_labels import number_of_labels\n",
    "from utils.message_preprocess import message_processing\n",
    "# plot untils funcion\n",
    "from utils.plot_utils import pie_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2952, 22)\n",
      "(2952, 22)\n",
      "(5904, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application</th>\n",
       "      <th>csha</th>\n",
       "      <th>commit message</th>\n",
       "      <th>maintenance</th>\n",
       "      <th>Bug fix</th>\n",
       "      <th>Documentation</th>\n",
       "      <th>Clean up</th>\n",
       "      <th>Source Control</th>\n",
       "      <th>Feature Add</th>\n",
       "      <th>Merge</th>\n",
       "      <th>Refactoring</th>\n",
       "      <th>Token Replace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>d84964855e190bf663d38b7fa37f3746deb2b3aa</td>\n",
       "      <td>chang look extend interfac first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>d1a63725ce21a1c6901ec762dd745ac58b8866b2</td>\n",
       "      <td>support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>47f75968703051dc09ed001ee84cce81e78835f7</td>\n",
       "      <td>mark</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>ee5c095b4237da991a911fa459514ca942ede7e0</td>\n",
       "      <td>remov thread warn report use think anyon under...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>fc1f4e841b3ef0f6fa4578b673e803c3df733a0d</td>\n",
       "      <td>make class statement call work correct fix</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               application                                      csha  \\\n",
       "0  google-closure-compiler  d84964855e190bf663d38b7fa37f3746deb2b3aa   \n",
       "1  google-closure-compiler  d1a63725ce21a1c6901ec762dd745ac58b8866b2   \n",
       "2  google-closure-compiler  47f75968703051dc09ed001ee84cce81e78835f7   \n",
       "3  google-closure-compiler  ee5c095b4237da991a911fa459514ca942ede7e0   \n",
       "4  google-closure-compiler  fc1f4e841b3ef0f6fa4578b673e803c3df733a0d   \n",
       "\n",
       "                                      commit message  maintenance  Bug fix  \\\n",
       "0                   chang look extend interfac first          1.0      0.0   \n",
       "1                                            support          1.0      0.0   \n",
       "2                                               mark          1.0      0.0   \n",
       "3  remov thread warn report use think anyon under...          0.0      0.0   \n",
       "4         make class statement call work correct fix          0.0      1.0   \n",
       "\n",
       "   Documentation  Clean up  Source Control  Feature Add  Merge  Refactoring  \\\n",
       "0            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "1            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "2            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "3            0.0       1.0             0.0          0.0    0.0          0.0   \n",
       "4            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "\n",
       "   Token Replace  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/Final_Label_10000.csv')\n",
    "df1 = df1[df1['Tagger ID'] == 'jy']\n",
    "print(df1.shape)\n",
    "df1.head()\n",
    "\n",
    "df2 = pd.read_csv('data/jincheng3000.csv')\n",
    "print(df2.shape)\n",
    "\n",
    "df =pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df = df.drop(['commit link_x', 'excluded','Commit ID','total_files','deleted_files','check', 'Tagger ID','commit link','testing', 'build'], axis = 1)\n",
    "df = df[['application', 'csha', 'commit message', 'maintenance', 'Bug fix', \n",
    "        'Documentation', 'Clean up','Source Control', 'Feature Add', 'Merge', 'Refactoring','Token Replace']]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 627\n",
      "Adaptive : 742\n",
      "Perfective : 3338\n",
      "Implementation : 864\n",
      "Non_functional : 95\n",
      "Other : 95\n"
     ]
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "def group_labels_new(df, labels_to_group, new_label):\n",
    "    '''\n",
    "    Group some of labels\n",
    "\n",
    "    Args:\n",
    "        df - dataframe\n",
    "        labels_to_group -  List of labels you want to group\n",
    "        new_label -  string - new label name of grouped labels\n",
    "\n",
    "    Returns:\n",
    "        new_df - dataframe after grouped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # generate new labels by group labels\n",
    "    def create_new_label(row, labels):\n",
    "        new_label = 0  # initialize new label\n",
    "        for label in labels:\n",
    "            if row[label] == 1:\n",
    "                new_label = 1  # if one of labels in grouped labels is 1 the new label is 1\n",
    "        return new_label\n",
    "\n",
    "    new_df[new_label] = df.apply(lambda row: create_new_label(row, labels_to_group), axis=1)\n",
    "\n",
    "    # generate list of new_categories\n",
    "\n",
    "    return new_df\n",
    "\n",
    "new_df = group_labels_new(new_df, ['Bug fix'], 'Corrective')\n",
    "new_df = group_labels_new(new_df, ['Documentation'], 'Adaptive')\n",
    "new_df = group_labels_new(new_df, ['Clean up', 'maintenance','Refactoring'], 'Perfective')\n",
    "new_df = group_labels_new(new_df, ['Feature Add'], 'Implementation')\n",
    "new_df = group_labels_new(new_df, ['Token Replace','Merge'], 'Non_functional')\n",
    "new_df = group_labels_new(new_df, ['Source Control'], 'Other')\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation','Non_functional','Other']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 627\n",
      "Adaptive : 742\n",
      "Perfective : 3338\n",
      "Implementation : 864\n",
      "1    5020\n",
      "0     613\n",
      "2     262\n",
      "3       9\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current number of samples: 5904\n",
      "number of samples after drop:5020\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Non-functional' and 'Other'\n",
    "\n",
    "new_df = new_df.drop(['Non_functional','Other'],axis = 1)\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = categories_count(new_df, target_col)\n",
    "\n",
    "# Drop rows with multiple labels\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = number_of_labels(new_df, target_col)\n",
    "\n",
    "print('current number of samples: %d'%new_df.shape[0])\n",
    "new_df['label_sum'] = new_df[target_col].sum(axis=1)\n",
    "new_df = new_df[new_df['label_sum']==1].reset_index(drop=True)\n",
    "print('number of samples after drop:%d'%new_df.shape[0])\n",
    "new_df = new_df.drop(['label_sum'], axis = 1)\n",
    "\n",
    "# Drop target col\n",
    "# new_df = new_df[new_df['Corrective']!=1].reset_index(drop=True)\n",
    "# target_col = ['Adaptive','Perfective','Implementation']\n",
    "\n",
    "# new_df = new_df[new_df['Implementation']!=1].reset_index(drop=True)\n",
    "# target_col = ['Adaptive','Perfective','Corrective']\n",
    "\n",
    "# form target cols\n",
    "new_df['target_class'] = np.argmax(new_df[target_col].values, axis = 1)\n",
    "new_df = new_df[~new_df['commit message'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-IDF and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, predicted))\n",
    "    print('F1-score macro:', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro:', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted:', f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop too long commits\n",
    "# new_df['len_seq'] = new_df.apply(lambda row: len(row['commit message'].split()), axis = 1)\n",
    "# new_df = new_df[new_df['len_seq'] >= 3].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape :  (4410, 28729)\n",
      "X test shape :  (490, 28729)\n"
     ]
    }
   ],
   "source": [
    "def tfidf_features(X):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test, and val sets and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=0, max_df=1.0, ngram_range=(1, 2),token_pattern='(\\S+)')\n",
    "    \n",
    "    X = tfidf_vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X,tfidf_vectorizer.vocabulary_\n",
    "\n",
    "X = new_df['commit message'].values\n",
    "y = new_df['target_class'].values\n",
    "X_tfidf, tfidf_vocab = tfidf_features(X)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('X train shape : ', X_train.shape)\n",
    "print('X test shape : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Accuracy: 0.7040816326530612\n",
      "F1-score macro: 0.4831495990571587\n",
      "F1-score micro: 0.7040816326530612\n",
      "F1-score weighted: 0.6607443676131267\n",
      "========================================================\n",
      "Accuracy: 0.6428571428571429\n",
      "F1-score macro: 0.44427745131939383\n",
      "F1-score micro: 0.6428571428571429\n",
      "F1-score weighted: 0.5856656128086379\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6551020408163265\n",
      "F1-score macro: 0.43879185809547927\n",
      "F1-score micro: 0.6551020408163265\n",
      "F1-score weighted: 0.6054860747612724\n",
      "========================================================\n",
      "Accuracy: 0.6571428571428571\n",
      "F1-score macro: 0.4596570416751431\n",
      "F1-score micro: 0.6571428571428571\n",
      "F1-score weighted: 0.6149135114336268\n",
      "========================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1c8a7a054d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_pre_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1606\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    331\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=10, random_state = 42, shuffle = True)\n",
    "skf.get_n_splits(X_tfidf, y)\n",
    "\n",
    "eval_result = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print('========================================================')\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    clf = LogisticRegression(penalty = 'l1', C = 2.5, random_state=0, solver='saga', multi_class='multinomial',max_iter=1000).fit(X_train, y_train)\n",
    "    y_pre_test = clf.predict(X_test)\n",
    "    predictions = clf.predict_proba(X_test) \n",
    "    print_evaluation_scores(y_test, y_pre_test)\n",
    "    \n",
    "    accu = accuracy_score(y_test, y_pre_test)\n",
    "    f1 = f1_score(y_test, y_pre_test, average='macro')\n",
    "    eval_result.append((accu, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6701996717767039\n",
      "0.4656351148498093\n"
     ]
    }
   ],
   "source": [
    "sum_acc = 0\n",
    "sum_f1 = 0\n",
    "for item in eval_result:\n",
    "    sum_acc += item[0]\n",
    "    sum_f1 += item[1]\n",
    "\n",
    "print(sum_acc/10)\n",
    "print(sum_f1/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logsitic Regression One VS Rest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/apple/venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/apple/venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.6707482993197279 \n",
      "\n",
      "Best parameters for training data: {'C': 5.5, 'multi_class': 'ovr', 'penalty': 'l1'} \n",
      "\n",
      "Best C: 5.5 \n",
      "\n",
      "Best penalty: l1 \n",
      "\n",
      "Accuracy: 0.7081632653061225\n",
      "F1-score macro: 0.5220289715581529\n",
      "F1-score micro: 0.7081632653061225\n",
      "F1-score weighted: 0.6755286254821168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'penalty': ['l1'], \n",
    "                'C': [1.5,2.5,3.5,4.5,5.5,6.5,8,10,15], \n",
    "                'multi_class':['multinomial','ovr']}]\n",
    "\n",
    "clf = LogisticRegression(random_state=0,solver='saga',n_jobs=-1,max_iter=1000)\n",
    "\n",
    "lr_model = GridSearchCV(clf, params_grid, cv=5)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# View the accuracy score\n",
    "print('Best score for training data:', lr_model.best_score_,\"\\n\") \n",
    "print('Best parameters for training data:',lr_model.best_params_,'\\n')\n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',lr_model.best_estimator_.C,\"\\n\") \n",
    "print('Best penalty:',lr_model.best_estimator_.penalty,\"\\n\")\n",
    "\n",
    "final_model = lr_model.best_estimator_\n",
    "Y_pred = lr_model.predict(X_test)\n",
    "print_evaluation_scores(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 5, 10, 20, 50, 100, 200, 500, 1000, 5000],\n",
       "                          'decision_function_shape': ['ovo', 'ovr'],\n",
       "                          'gamma': [0.1, 0.01, 0.001, 0.0001, 1e-05],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 5, 10, 20, 50, 100, 200, 500, 1000, 5000],\n",
       "                          'decision_function_shape': ['ovo', 'ovr'],\n",
       "                          'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5], 'C': [1, 5, 10, 20, 50, 100, 200, 500, 1000, 5000], 'decision_function_shape':['ovo','ovr']},\n",
    "               {'kernel': ['linear'], 'C': [1, 5, 10, 20, 50, 100, 200, 500, 1000, 5000], 'decision_function_shape':['ovo','ovr']}]\n",
    "\n",
    "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.6798185941043083 \n",
      "\n",
      "Best parameters for training data: {'C': 10, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'kernel': 'rbf'} \n",
      "\n",
      "Best C: 10 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.1 \n",
      "\n",
      "Accuracy: 0.7122448979591837\n",
      "F1-score macro: 0.5106395429119893\n",
      "F1-score micro: 0.7122448979591838\n",
      "F1-score weighted: 0.6714444755973846\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "print('Best parameters for training data:',svm_model.best_params_,'\\n')\n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "Y_pred = final_model.predict(X_test)\n",
    "print_evaluation_scores(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "seed_value= 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 09:45:31.154328 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 09:45:31.158000 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 09:45:31.181859 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 09:45:31.378143 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0819 09:45:31.466506 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 09:45:31.479389 4335547840 deprecation_wrapper.py:119] From /Users/apple/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               243200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 247,812\n",
      "Trainable params: 246,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "X train shape :  (4410, 28537)\n",
      "X test shape :  (490, 28537)\n",
      "X train shape :  (3969, 28537)\n",
      "X val shape :  (441, 28537)\n"
     ]
    }
   ],
   "source": [
    "def tfidf_features(X):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test, and val sets and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=0, max_df=1.0, ngram_range=(1, 2))\n",
    "    \n",
    "    X = tfidf_vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X,tfidf_vectorizer.vocabulary_\n",
    "\n",
    "def dense_layer(n_input, \n",
    "                hidden_layers = [512], \n",
    "                dropout_rate = 0, \n",
    "                l2_penalty = 0.1, \n",
    "                optimizer = 'adam',\n",
    "                lr = 0.001,\n",
    "                n_class = 4): \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layers\n",
    "    for index, hidden_units in enumerate(hidden_layers):       \n",
    "        if index == 0:\n",
    "            # specify the input_dim to be the number of features for the first layer\n",
    "            model.add(Dense(hidden_units, input_dim = n_input, kernel_regularizer = l2(l2_penalty)))\n",
    "        else:\n",
    "            model.add(Dense(hidden_units, kernel_regularizer = l2(l2_penalty)))\n",
    "        \n",
    "        # insert BatchNorm layer immediately after fully connected layers\n",
    "        # and before activation layer\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(PReLU())        \n",
    "        if dropout_rate != 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # finial layers\n",
    "    model.add(Dense(n_class, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "                    optimizer= optimizers.Adam(lr=lr),\n",
    "                    metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "dense_layer(474).summary()\n",
    "X = new_df['commit message'].values\n",
    "y = new_df[target_col].values\n",
    "X_tfidf, tfidf_vocab = tfidf_features(X)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('X train shape : ', X_train.shape)\n",
    "print('X test shape : ', X_test.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)\n",
    "\n",
    "print('X train shape : ', X_train.shape)\n",
    "print('X val shape : ', X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3969 samples, validate on 441 samples\n",
      "Epoch 1/200\n",
      " - 15s - loss: 95.5121 - acc: 0.5649 - val_loss: 11.6083 - val_acc: 0.6576\n",
      "Epoch 2/200\n",
      " - 12s - loss: 12.4152 - acc: 0.6893 - val_loss: 5.7216 - val_acc: 0.6599\n",
      "Epoch 3/200\n",
      " - 9s - loss: 3.1621 - acc: 0.6805 - val_loss: 2.4880 - val_acc: 0.6485\n",
      "Epoch 4/200\n",
      " - 9s - loss: 1.9462 - acc: 0.6697 - val_loss: 1.7070 - val_acc: 0.6576\n",
      "Epoch 5/200\n",
      " - 9s - loss: 1.6472 - acc: 0.6684 - val_loss: 1.6937 - val_acc: 0.6712\n",
      "Epoch 6/200\n",
      " - 11s - loss: 1.6593 - acc: 0.6780 - val_loss: 1.7389 - val_acc: 0.6712\n",
      "Epoch 7/200\n",
      " - 10s - loss: 1.7105 - acc: 0.6805 - val_loss: 1.7967 - val_acc: 0.6735\n",
      "Epoch 8/200\n",
      " - 9s - loss: 1.7535 - acc: 0.6848 - val_loss: 1.8410 - val_acc: 0.6803\n",
      "Epoch 9/200\n",
      " - 9s - loss: 1.7944 - acc: 0.6878 - val_loss: 1.8891 - val_acc: 0.6871\n",
      "Epoch 10/200\n",
      " - 9s - loss: 1.8300 - acc: 0.6863 - val_loss: 1.9307 - val_acc: 0.6757\n",
      "Epoch 11/200\n",
      " - 12s - loss: 1.8663 - acc: 0.6896 - val_loss: 1.9637 - val_acc: 0.6984\n",
      "Epoch 12/200\n",
      " - 13s - loss: 1.8691 - acc: 0.6936 - val_loss: 1.9740 - val_acc: 0.6825\n",
      "Epoch 13/200\n",
      " - 11s - loss: 1.8922 - acc: 0.7014 - val_loss: 2.0146 - val_acc: 0.6939\n",
      "Epoch 14/200\n",
      " - 12s - loss: 1.9059 - acc: 0.6969 - val_loss: 2.0246 - val_acc: 0.6939\n",
      "Epoch 15/200\n",
      " - 11s - loss: 1.9161 - acc: 0.7047 - val_loss: 2.0547 - val_acc: 0.6871\n",
      "Accuracy: 0.6918367346938775\n",
      "F1-score macro: 0.4091433457897062\n",
      "F1-score micro: 0.6918367346938775\n",
      "F1-score weighted: 0.6188312751526428\n"
     ]
    }
   ],
   "source": [
    "dense_network = dense_layer(X_train.shape[1],n_class = 4,\n",
    "                            hidden_layers = [512], \n",
    "                            dropout_rate = 0.5, \n",
    "                            l2_penalty = 0.3)\n",
    "early_stop = EarlyStopping(monitor = 'val_acc', min_delta = 0.01, patience = 10, verbose = 0, restore_best_weights = True)\n",
    "\n",
    "history = dense_network.fit(X_train, y_train, batch_size=256, epochs=200,\n",
    "                            validation_data=(X_val, y_val), verbose=2, shuffle = False, callbacks = [early_stop])\n",
    "\n",
    "y_pred = np.argmax(dense_network.predict(X_test), axis = 1)\n",
    "y_test_new = np.argmax(y_test, axis = 1)\n",
    "print_evaluation_scores(y_test_new, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
