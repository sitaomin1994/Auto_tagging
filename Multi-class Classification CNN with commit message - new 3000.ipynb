{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# funtions to handle labels\n",
    "from utils.handle_labels import get_tag_counts_and_labels\n",
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from utils.handle_labels import categories_count\n",
    "from utils.handle_labels import get_imbalance\n",
    "from utils.handle_labels import label_distribution\n",
    "from utils.handle_labels import number_of_labels\n",
    "from utils.message_preprocess import message_processing\n",
    "# plot untils funcion\n",
    "from utils.plot_utils import pie_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2952, 22)\n",
      "(2952, 22)\n",
      "(5904, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application</th>\n",
       "      <th>csha</th>\n",
       "      <th>commit message</th>\n",
       "      <th>maintenance</th>\n",
       "      <th>Bug fix</th>\n",
       "      <th>Documentation</th>\n",
       "      <th>Clean up</th>\n",
       "      <th>Source Control</th>\n",
       "      <th>Feature Add</th>\n",
       "      <th>Merge</th>\n",
       "      <th>Refactoring</th>\n",
       "      <th>Token Replace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>d84964855e190bf663d38b7fa37f3746deb2b3aa</td>\n",
       "      <td>chang look extend interfac first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>d1a63725ce21a1c6901ec762dd745ac58b8866b2</td>\n",
       "      <td>support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>47f75968703051dc09ed001ee84cce81e78835f7</td>\n",
       "      <td>mark</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>ee5c095b4237da991a911fa459514ca942ede7e0</td>\n",
       "      <td>remov thread warn report use think anyon under...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-closure-compiler</td>\n",
       "      <td>fc1f4e841b3ef0f6fa4578b673e803c3df733a0d</td>\n",
       "      <td>make class statement call work correct fix</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               application                                      csha  \\\n",
       "0  google-closure-compiler  d84964855e190bf663d38b7fa37f3746deb2b3aa   \n",
       "1  google-closure-compiler  d1a63725ce21a1c6901ec762dd745ac58b8866b2   \n",
       "2  google-closure-compiler  47f75968703051dc09ed001ee84cce81e78835f7   \n",
       "3  google-closure-compiler  ee5c095b4237da991a911fa459514ca942ede7e0   \n",
       "4  google-closure-compiler  fc1f4e841b3ef0f6fa4578b673e803c3df733a0d   \n",
       "\n",
       "                                      commit message  maintenance  Bug fix  \\\n",
       "0                   chang look extend interfac first          1.0      0.0   \n",
       "1                                            support          1.0      0.0   \n",
       "2                                               mark          1.0      0.0   \n",
       "3  remov thread warn report use think anyon under...          0.0      0.0   \n",
       "4         make class statement call work correct fix          0.0      1.0   \n",
       "\n",
       "   Documentation  Clean up  Source Control  Feature Add  Merge  Refactoring  \\\n",
       "0            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "1            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "2            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "3            0.0       1.0             0.0          0.0    0.0          0.0   \n",
       "4            0.0       0.0             0.0          0.0    0.0          0.0   \n",
       "\n",
       "   Token Replace  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/Final_Label_10000.csv')\n",
    "df1 = df1[df1['Tagger ID'] == 'jy']\n",
    "print(df1.shape)\n",
    "df1.head()\n",
    "\n",
    "df2 = pd.read_csv('data/jincheng3000.csv')\n",
    "print(df2.shape)\n",
    "\n",
    "df =pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df = df.drop(['commit link_x', 'excluded','Commit ID','total_files','deleted_files','check', 'Tagger ID','commit link','testing', 'build'], axis = 1)\n",
    "df = df[['application', 'csha', 'commit message', 'maintenance', 'Bug fix', \n",
    "        'Documentation', 'Clean up','Source Control', 'Feature Add', 'Merge', 'Refactoring','Token Replace']]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 627\n",
      "Adaptive : 742\n",
      "Perfective : 3338\n",
      "Implementation : 864\n",
      "Non_functional : 95\n",
      "Other : 95\n"
     ]
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "def group_labels_new(df, labels_to_group, new_label):\n",
    "    '''\n",
    "    Group some of labels\n",
    "\n",
    "    Args:\n",
    "        df - dataframe\n",
    "        labels_to_group -  List of labels you want to group\n",
    "        new_label -  string - new label name of grouped labels\n",
    "\n",
    "    Returns:\n",
    "        new_df - dataframe after grouped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # generate new labels by group labels\n",
    "    def create_new_label(row, labels):\n",
    "        new_label = 0  # initialize new label\n",
    "        for label in labels:\n",
    "            if row[label] == 1:\n",
    "                new_label = 1  # if one of labels in grouped labels is 1 the new label is 1\n",
    "        return new_label\n",
    "\n",
    "    new_df[new_label] = df.apply(lambda row: create_new_label(row, labels_to_group), axis=1)\n",
    "\n",
    "    # generate list of new_categories\n",
    "\n",
    "    return new_df\n",
    "\n",
    "new_df = group_labels_new(new_df, ['Bug fix'], 'Corrective')\n",
    "new_df = group_labels_new(new_df, ['Documentation'], 'Adaptive')\n",
    "new_df = group_labels_new(new_df, ['Clean up', 'maintenance','Refactoring'], 'Perfective')\n",
    "new_df = group_labels_new(new_df, ['Feature Add'], 'Implementation')\n",
    "new_df = group_labels_new(new_df, ['Token Replace','Merge'], 'Non_functional')\n",
    "new_df = group_labels_new(new_df, ['Source Control'], 'Other')\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation','Non_functional','Other']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 627\n",
      "Adaptive : 742\n",
      "Perfective : 3338\n",
      "Implementation : 864\n",
      "1    5020\n",
      "0     613\n",
      "2     262\n",
      "3       9\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current number of samples: 5904\n",
      "number of samples after drop:5020\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Non-functional' and 'Other'\n",
    "\n",
    "new_df = new_df.drop(['Non_functional','Other'],axis = 1)\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = categories_count(new_df, target_col)\n",
    "\n",
    "# Drop rows with multiple labels\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = number_of_labels(new_df, target_col)\n",
    "\n",
    "print('current number of samples: %d'%new_df.shape[0])\n",
    "new_df['label_sum'] = new_df[target_col].sum(axis=1)\n",
    "new_df = new_df[new_df['label_sum']==1].reset_index(drop=True)\n",
    "print('number of samples after drop:%d'%new_df.shape[0])\n",
    "new_df = new_df.drop(['label_sum'], axis = 1)\n",
    "\n",
    "# Drop target col\n",
    "# new_df = new_df[new_df['Corrective']!=1].reset_index(drop=True)\n",
    "# target_col = ['Adaptive','Perfective','Implementation']\n",
    "\n",
    "# new_df = new_df[new_df['Perfective']!=1].reset_index(drop=True)\n",
    "# target_col = ['Adaptive','Implementation','Corrective']\n",
    "\n",
    "# form target cols\n",
    "new_df['target_class'] = np.argmax(new_df[target_col].values, axis = 1)\n",
    "new_df = new_df[~new_df['commit message'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Tokenize and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "    plt.xlim((0, 500))\n",
    "    plt.ylim((0, 200))\n",
    "\n",
    "number_of_words = [len(message.split()) for message in new_df['commit message'].values]\n",
    "plot_hist(number_of_words)\n",
    "\n",
    "# getting file threshold\n",
    "threshold = 0.95\n",
    "\n",
    "def get_file_threshold(number_of_files, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for files dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_files - array of the number of files in each commits\n",
    "        threshold - drop all commits with its the number of files beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_files = len(number_of_files)\n",
    "    number_of_files = np.array(number_of_files)\n",
    "    bincount = np.bincount(number_of_files)\n",
    "\n",
    "    sum_file = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_file += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_file > threshold*total_files:\n",
    "            padding_files_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_files_threshold\n",
    "\n",
    "length_threshold = get_file_threshold(number_of_words, threshold)\n",
    "print(length_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop too long commits\n",
    "new_df['len_seq'] = new_df.apply(lambda row: len(row['commit message'].split()), axis = 1)\n",
    "new_df = new_df[new_df['len_seq'] >= 1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 276, 189, 73, 113]\n",
      "[  7 276 189  73 113   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "(4900, 26)\n",
      "Vocab_size : 2553\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "docs = new_df['commit message'].values\n",
    "t = Tokenizer(filters = '', lower=False)\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "sequences = t.texts_to_sequences(docs)\n",
    "print(sequences[0])\n",
    "\n",
    "#Pad data \n",
    "padded_seq = pad_sequences(sequences, maxlen= length_threshold, padding=\"post\", truncating=\"post\")\n",
    "print(padded_seq[0])\n",
    "print(padded_seq.shape)\n",
    "\n",
    "# vocabulary\n",
    "vocabulary = t.word_index\n",
    "vocabulary_inv = dict((v, k) for k, v in vocabulary.items())\n",
    "vocabulary_inv[0] = \"<PAD/>\"\n",
    "\n",
    "print('Vocab_size : %d'%len(vocabulary_inv.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_seq\n",
    "y = new_df[target_col].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# print('X train shape : ', X_train.shape)\n",
    "# print('X test shape : ', X_test.shape)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)\n",
    "# print('X train shape : ', X_train.shape)\n",
    "# print('X val shape : ', X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D,GlobalMaxPooling1D, Convolution1D, Embedding, Reshape,Conv2D, MaxPool2D\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "seed_value= 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, predicted))\n",
    "    print('F1-score macro:', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro:', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted:', f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 100, 64)      32000       input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 100, 128)     41088       embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 100, 128)     41088       embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 100, 128)     41088       embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_73 (Global (None, 128)          0           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_74 (Global (None, 128)          0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_75 (Global (None, 128)          0           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 384)          0           global_max_pooling1d_73[0][0]    \n",
      "                                                                 global_max_pooling1d_74[0][0]    \n",
      "                                                                 global_max_pooling1d_75[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 384)          0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          49280       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 4)            516         dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 205,060\n",
      "Trainable params: 205,060\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CNN_model(sequence_length, vocab_size, \n",
    "              embedding_dim = 64, \n",
    "              filter_sizes = (5,5,5),  \n",
    "              num_filters = 128,  \n",
    "              drop_prob = 0.4, \n",
    "              hidden_dims = 128, \n",
    "              n_class = 4):\n",
    "    \n",
    "    # input\n",
    "    inputs = Input(shape=(sequence_length, ),  dtype='int32')\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for filter_size in filter_sizes: # Feature > Maintenance > Clean  up > Bug fix > \n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=filter_size,\n",
    "                         padding=\"same\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1,\n",
    "                         use_bias=True)(embedding)\n",
    "        \n",
    "        conv = GlobalMaxPooling1D()(conv) # 1-Max pooling\n",
    "\n",
    "        conv_blocks.append(conv)\n",
    "\n",
    "    concatenate = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "    \n",
    "    dropout = Dropout(drop_prob)(concatenate)\n",
    "    \n",
    "    output_layer = Dense(hidden_dims, activation='relu',\n",
    "                         kernel_regularizer=regularizers.l2(0.1),bias_regularizer=regularizers.l1(0.1)\n",
    "                        )(dropout)\n",
    "    \n",
    "\n",
    "    output = Dense(n_class, activation=\"softmax\")(output_layer)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= adam, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn = CNN_model(100, 500)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3931 samples, validate on 437 samples\n",
      "Epoch 1/200\n",
      "3931/3931 [==============================] - 23s 6ms/step - loss: 18.2121 - acc: 0.6634 - val_loss: 12.8522 - val_acc: 0.6888\n",
      "Epoch 2/200\n",
      "3931/3931 [==============================] - 17s 4ms/step - loss: 9.6955 - acc: 0.7011 - val_loss: 6.6077 - val_acc: 0.6888\n",
      "Epoch 3/200\n",
      "3931/3931 [==============================] - 17s 4ms/step - loss: 4.8980 - acc: 0.7049 - val_loss: 3.3358 - val_acc: 0.6819\n",
      "Epoch 4/200\n",
      "3931/3931 [==============================] - 17s 4ms/step - loss: 2.4480 - acc: 0.7454 - val_loss: 1.7723 - val_acc: 0.7140\n",
      "Epoch 5/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 1.2769 - acc: 0.7942 - val_loss: 1.1246 - val_acc: 0.7254\n",
      "Epoch 6/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.7529 - acc: 0.8367 - val_loss: 0.9447 - val_acc: 0.7300\n",
      "Epoch 7/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.5261 - acc: 0.8586 - val_loss: 0.9333 - val_acc: 0.7254\n",
      "Epoch 8/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.4278 - acc: 0.8733 - val_loss: 0.8622 - val_acc: 0.6911\n",
      "Epoch 9/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.3589 - acc: 0.8962 - val_loss: 0.8786 - val_acc: 0.7002\n",
      "Epoch 10/200\n",
      "3931/3931 [==============================] - 20s 5ms/step - loss: 0.3107 - acc: 0.9161 - val_loss: 0.9812 - val_acc: 0.7231\n",
      "Epoch 11/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.2780 - acc: 0.9255 - val_loss: 1.0019 - val_acc: 0.7231\n",
      "Epoch 12/200\n",
      "3931/3931 [==============================] - 22s 6ms/step - loss: 0.2514 - acc: 0.9359 - val_loss: 1.0094 - val_acc: 0.6934\n",
      "Epoch 13/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.2310 - acc: 0.9382 - val_loss: 1.0268 - val_acc: 0.6819\n",
      "Epoch 14/200\n",
      "3931/3931 [==============================] - 19s 5ms/step - loss: 0.2179 - acc: 0.9461 - val_loss: 1.1107 - val_acc: 0.7025\n",
      "Epoch 15/200\n",
      "3931/3931 [==============================] - 20s 5ms/step - loss: 0.2129 - acc: 0.9453 - val_loss: 1.2993 - val_acc: 0.7391\n",
      "Epoch 16/200\n",
      "3931/3931 [==============================] - 20s 5ms/step - loss: 0.2226 - acc: 0.9392 - val_loss: 1.2233 - val_acc: 0.6911\n",
      "Epoch 17/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1994 - acc: 0.9491 - val_loss: 1.1870 - val_acc: 0.6911\n",
      "Epoch 18/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1738 - acc: 0.9590 - val_loss: 1.2944 - val_acc: 0.7346\n",
      "Epoch 19/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1632 - acc: 0.9601 - val_loss: 1.2636 - val_acc: 0.7025\n",
      "Epoch 20/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1527 - acc: 0.9641 - val_loss: 1.2560 - val_acc: 0.7025\n",
      "Epoch 21/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1455 - acc: 0.9649 - val_loss: 1.2830 - val_acc: 0.7140\n",
      "Epoch 22/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1385 - acc: 0.9651 - val_loss: 1.3239 - val_acc: 0.7208\n",
      "Epoch 23/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1350 - acc: 0.9641 - val_loss: 1.3880 - val_acc: 0.7140\n",
      "Epoch 24/200\n",
      "3931/3931 [==============================] - 22s 6ms/step - loss: 0.1327 - acc: 0.9644 - val_loss: 1.4257 - val_acc: 0.7231\n",
      "Epoch 25/200\n",
      "3931/3931 [==============================] - 21s 5ms/step - loss: 0.1313 - acc: 0.9672 - val_loss: 1.5280 - val_acc: 0.7323\n",
      "Accuracy: 0.7391304347826086\n",
      "F1-score macro: 0.5560712677764355\n",
      "F1-score micro: 0.7391304347826085\n",
      "F1-score weighted: 0.6973308124267803\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN_model(X_train.shape[1],\n",
    "                      len(vocabulary_inv.keys()),\n",
    "                      embedding_dim = 256, \n",
    "                      filter_sizes = (5,5,5),  \n",
    "                      num_filters = 256,  \n",
    "                      drop_prob = 0.4, \n",
    "                      hidden_dims = 128, n_class = 4)\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_acc', min_delta = 0.01, patience = 10, verbose = 0, restore_best_weights = True)\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "history = cnn_model.fit(X_train, y_train, batch_size=256, epochs=200,\n",
    "                            validation_data=(X_test, y_test), verbose=1, shuffle = False, callbacks = [early_stop])\n",
    "\n",
    "y_pred = np.argmax(cnn_model.predict(X_test), axis = 1)\n",
    "y_test_new = np.argmax(y_test, axis = 1)\n",
    "print_evaluation_scores(y_test_new, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "def cnn_train(X_train, y_train, X_test, y_test):\n",
    "    cnn_model = CNN_model(X_train.shape[1],\n",
    "                          len(vocabulary_inv.keys()),\n",
    "                          embedding_dim = 128, \n",
    "                          filter_sizes = (5,5,5),  \n",
    "                          num_filters = 256,  \n",
    "                          drop_prob = 0.4, \n",
    "                          hidden_dims = 128, n_class = 4)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor = 'val_acc', min_delta = 0.01, patience = 10, verbose = 0, restore_best_weights = True)\n",
    "    checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "    history = cnn_model.fit(X_train, y_train, batch_size=256, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=1, shuffle = False, callbacks = [early_stop])\n",
    "\n",
    "    y_pred = np.argmax(cnn_model.predict(X_test), axis = 1)\n",
    "    y_test_new = np.argmax(y_test, axis = 1)\n",
    "    print_evaluation_scores(y_test_new, y_pred)\n",
    "    \n",
    "    accu = accuracy_score(y_test_new, y_pred)\n",
    "    f1 = f1_score(y_test_new, y_pred, average='macro')\n",
    "    \n",
    "    return accu, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Train on 4407 samples, validate on 493 samples\n",
      "Epoch 1/20\n",
      "4407/4407 [==============================] - 14s 3ms/step - loss: 17.8570 - acc: 0.5963 - val_loss: 12.0693 - val_acc: 0.6207\n",
      "Epoch 2/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 8.8841 - acc: 0.6236 - val_loss: 5.8055 - val_acc: 0.6207\n",
      "Epoch 3/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 4.3007 - acc: 0.6149 - val_loss: 2.8682 - val_acc: 0.6207\n",
      "Epoch 4/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 2.2289 - acc: 0.5954 - val_loss: 1.6388 - val_acc: 0.6389\n",
      "Epoch 5/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 1.3639 - acc: 0.6324 - val_loss: 1.1675 - val_acc: 0.6308\n",
      "Epoch 6/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 1.0201 - acc: 0.6415 - val_loss: 1.0287 - val_acc: 0.6491\n",
      "Epoch 7/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.8805 - acc: 0.6669 - val_loss: 1.0219 - val_acc: 0.6410\n",
      "Epoch 8/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.8265 - acc: 0.6980 - val_loss: 1.0400 - val_acc: 0.6349\n",
      "Epoch 9/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.7705 - acc: 0.7329 - val_loss: 1.0835 - val_acc: 0.6410\n",
      "Epoch 10/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.7385 - acc: 0.7524 - val_loss: 1.1036 - val_acc: 0.6450\n",
      "Epoch 11/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.6658 - acc: 0.7794 - val_loss: 1.1369 - val_acc: 0.6207\n",
      "Epoch 12/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.6478 - acc: 0.7987 - val_loss: 1.1729 - val_acc: 0.6045\n",
      "Epoch 13/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.6123 - acc: 0.8094 - val_loss: 1.2039 - val_acc: 0.6146\n",
      "Epoch 14/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.6045 - acc: 0.8210 - val_loss: 1.4329 - val_acc: 0.6613\n",
      "Epoch 15/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.5960 - acc: 0.8282 - val_loss: 1.1366 - val_acc: 0.6491\n",
      "Epoch 16/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.4893 - acc: 0.8704 - val_loss: 1.1718 - val_acc: 0.6349\n",
      "Epoch 17/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.4509 - acc: 0.8877 - val_loss: 1.3157 - val_acc: 0.6369\n",
      "Epoch 18/20\n",
      "4407/4407 [==============================] - 11s 2ms/step - loss: 0.4278 - acc: 0.8952 - val_loss: 1.2710 - val_acc: 0.6491\n",
      "Epoch 19/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.3923 - acc: 0.9061 - val_loss: 1.2344 - val_acc: 0.6531\n",
      "Epoch 20/20\n",
      "4407/4407 [==============================] - 15s 3ms/step - loss: 0.3618 - acc: 0.9194 - val_loss: 1.2719 - val_acc: 0.6389\n",
      "Accuracy: 0.6389452332657201\n",
      "F1-score macro: 0.5116104833570099\n",
      "F1-score micro: 0.6389452332657201\n",
      "F1-score weighted: 0.6268271231886349\n",
      "========================================================\n",
      "Train on 4407 samples, validate on 493 samples\n",
      "Epoch 1/20\n",
      "4407/4407 [==============================] - 17s 4ms/step - loss: 17.8516 - acc: 0.5750 - val_loss: 12.0322 - val_acc: 0.6207\n",
      "Epoch 2/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 8.8916 - acc: 0.6233 - val_loss: 5.7982 - val_acc: 0.6207\n",
      "Epoch 3/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 4.3243 - acc: 0.6224 - val_loss: 2.8809 - val_acc: 0.6207\n",
      "Epoch 4/20\n",
      "4407/4407 [==============================] - 14s 3ms/step - loss: 2.2681 - acc: 0.6004 - val_loss: 1.6528 - val_acc: 0.6288\n",
      "Epoch 5/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 1.3931 - acc: 0.6124 - val_loss: 1.2027 - val_acc: 0.6329\n",
      "Epoch 6/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 1.0470 - acc: 0.6388 - val_loss: 1.0471 - val_acc: 0.6349\n",
      "Epoch 7/20\n",
      "4407/4407 [==============================] - 11s 3ms/step - loss: 0.8972 - acc: 0.6748 - val_loss: 1.0217 - val_acc: 0.6410\n",
      "Epoch 8/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.8231 - acc: 0.7166 - val_loss: 1.0531 - val_acc: 0.6349\n",
      "Epoch 9/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.7584 - acc: 0.7524 - val_loss: 1.0834 - val_acc: 0.6410\n",
      "Epoch 10/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.6897 - acc: 0.7912 - val_loss: 1.1191 - val_acc: 0.6471\n",
      "Epoch 11/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.6348 - acc: 0.8148 - val_loss: 1.1763 - val_acc: 0.6430\n",
      "Epoch 12/20\n",
      "4407/4407 [==============================] - 14s 3ms/step - loss: 0.5908 - acc: 0.8403 - val_loss: 1.2085 - val_acc: 0.6531\n",
      "Epoch 13/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.5390 - acc: 0.8566 - val_loss: 1.1899 - val_acc: 0.6633\n",
      "Epoch 14/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.4879 - acc: 0.8784 - val_loss: 1.1806 - val_acc: 0.6471\n",
      "Epoch 15/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.4666 - acc: 0.8829 - val_loss: 1.2617 - val_acc: 0.6207\n",
      "Epoch 16/20\n",
      "4407/4407 [==============================] - 13s 3ms/step - loss: 0.4645 - acc: 0.8881 - val_loss: 1.4997 - val_acc: 0.6592\n",
      "Epoch 17/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.5040 - acc: 0.8618 - val_loss: 1.2564 - val_acc: 0.6471\n",
      "Epoch 18/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.4232 - acc: 0.8963 - val_loss: 1.2777 - val_acc: 0.6531\n",
      "Epoch 19/20\n",
      "4407/4407 [==============================] - 25s 6ms/step - loss: 0.3476 - acc: 0.9263 - val_loss: 1.2741 - val_acc: 0.6572\n",
      "Epoch 20/20\n",
      "4407/4407 [==============================] - 12s 3ms/step - loss: 0.3129 - acc: 0.9326 - val_loss: 1.3680 - val_acc: 0.6511\n",
      "Accuracy: 0.6511156186612576\n",
      "F1-score macro: 0.5067415573368546\n",
      "F1-score micro: 0.6511156186612576\n",
      "F1-score weighted: 0.627738443160572\n",
      "========================================================\n",
      "Train on 4409 samples, validate on 491 samples\n",
      "Epoch 1/20\n",
      "4409/4409 [==============================] - 18s 4ms/step - loss: 17.8231 - acc: 0.5797 - val_loss: 12.0301 - val_acc: 0.6232\n",
      "Epoch 2/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 8.8725 - acc: 0.6230 - val_loss: 5.7752 - val_acc: 0.6232\n",
      "Epoch 3/20\n",
      "4409/4409 [==============================] - 17s 4ms/step - loss: 4.2954 - acc: 0.6108 - val_loss: 2.8355 - val_acc: 0.6273\n",
      "Epoch 4/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 2.2389 - acc: 0.6006 - val_loss: 1.6033 - val_acc: 0.6660\n",
      "Epoch 5/20\n",
      "4409/4409 [==============================] - 20s 4ms/step - loss: 1.3757 - acc: 0.6240 - val_loss: 1.1274 - val_acc: 0.6619\n",
      "Epoch 6/20\n",
      "4409/4409 [==============================] - 19s 4ms/step - loss: 1.0253 - acc: 0.6537 - val_loss: 0.9938 - val_acc: 0.6619\n",
      "Epoch 7/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.9052 - acc: 0.6591 - val_loss: 1.0002 - val_acc: 0.6354\n",
      "Epoch 8/20\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.8425 - acc: 0.7029 - val_loss: 1.0026 - val_acc: 0.6477\n",
      "Epoch 9/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.7690 - acc: 0.7478 - val_loss: 1.0210 - val_acc: 0.6436\n",
      "Epoch 10/20\n",
      "4409/4409 [==============================] - 12s 3ms/step - loss: 0.7127 - acc: 0.7780 - val_loss: 1.0976 - val_acc: 0.6273\n",
      "Epoch 11/20\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.6790 - acc: 0.7966 - val_loss: 1.1004 - val_acc: 0.6314\n",
      "Epoch 12/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.6159 - acc: 0.8333 - val_loss: 1.1361 - val_acc: 0.6232\n",
      "Epoch 13/20\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.5557 - acc: 0.8580 - val_loss: 1.1291 - val_acc: 0.6497\n",
      "Epoch 14/20\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.4997 - acc: 0.8782 - val_loss: 1.1935 - val_acc: 0.6660\n",
      "Accuracy: 0.6659877800407332\n",
      "F1-score macro: 0.3417286055642944\n",
      "F1-score micro: 0.6659877800407332\n",
      "F1-score weighted: 0.5600484273166317\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4411/4411 [==============================] - 17s 4ms/step - loss: 17.9445 - acc: 0.5865 - val_loss: 12.1290 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 8.9237 - acc: 0.6228 - val_loss: 5.8549 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 4.3429 - acc: 0.6119 - val_loss: 2.8936 - val_acc: 0.6217\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 2.2733 - acc: 0.5976 - val_loss: 1.6553 - val_acc: 0.6585\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 1.3784 - acc: 0.6300 - val_loss: 1.1854 - val_acc: 0.6339\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.0378 - acc: 0.6448 - val_loss: 1.0511 - val_acc: 0.6217\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.8937 - acc: 0.6620 - val_loss: 1.0119 - val_acc: 0.6360\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.7967 - acc: 0.7114 - val_loss: 1.0667 - val_acc: 0.6012\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.7478 - acc: 0.7352 - val_loss: 1.1149 - val_acc: 0.6012\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.6851 - acc: 0.7647 - val_loss: 1.1707 - val_acc: 0.6135\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.6281 - acc: 0.8055 - val_loss: 1.2135 - val_acc: 0.6258\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.5789 - acc: 0.8345 - val_loss: 1.2631 - val_acc: 0.6196\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.5443 - acc: 0.8560 - val_loss: 1.3029 - val_acc: 0.6299\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.5163 - acc: 0.8699 - val_loss: 1.3500 - val_acc: 0.6053\n",
      "Accuracy: 0.6584867075664622\n",
      "F1-score macro: 0.3218778786682458\n",
      "F1-score micro: 0.6584867075664622\n",
      "F1-score weighted: 0.5504327202669816\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 17.9392 - acc: 0.5779 - val_loss: 12.1341 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 8.9410 - acc: 0.6228 - val_loss: 5.8564 - val_acc: 0.6258\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 4.3408 - acc: 0.6060 - val_loss: 2.9012 - val_acc: 0.6278\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 2.2565 - acc: 0.6076 - val_loss: 1.6764 - val_acc: 0.6319\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.3712 - acc: 0.6323 - val_loss: 1.2107 - val_acc: 0.6442\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.0234 - acc: 0.6570 - val_loss: 1.0949 - val_acc: 0.6155\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.9016 - acc: 0.6652 - val_loss: 1.1031 - val_acc: 0.6339\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 0.8460 - acc: 0.7010 - val_loss: 1.1034 - val_acc: 0.6237\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 0.7839 - acc: 0.7359 - val_loss: 1.1359 - val_acc: 0.6258\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.7127 - acc: 0.7749 - val_loss: 1.1465 - val_acc: 0.6319\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 0.6340 - acc: 0.8182 - val_loss: 1.1738 - val_acc: 0.6299\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 0.5765 - acc: 0.8474 - val_loss: 1.2288 - val_acc: 0.6074\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 10s 2ms/step - loss: 0.5261 - acc: 0.8706 - val_loss: 1.2961 - val_acc: 0.6115\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 0.4902 - acc: 0.8796 - val_loss: 1.3350 - val_acc: 0.6299\n",
      "Epoch 15/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.4529 - acc: 0.8966 - val_loss: 1.4101 - val_acc: 0.6483\n",
      "Accuracy: 0.6441717791411042\n",
      "F1-score macro: 0.3199309319600132\n",
      "F1-score micro: 0.6441717791411042\n",
      "F1-score weighted: 0.5455823029205454\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 17.9071 - acc: 0.5935 - val_loss: 12.0981 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 8.9114 - acc: 0.6230 - val_loss: 5.8242 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 4.3153 - acc: 0.6037 - val_loss: 2.8652 - val_acc: 0.6217\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 2.2391 - acc: 0.5994 - val_loss: 1.6231 - val_acc: 0.6462\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.3640 - acc: 0.6248 - val_loss: 1.1514 - val_acc: 0.6339\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.0283 - acc: 0.6230 - val_loss: 1.0013 - val_acc: 0.6564\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.8792 - acc: 0.6692 - val_loss: 1.0053 - val_acc: 0.6728\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.8142 - acc: 0.7069 - val_loss: 1.0507 - val_acc: 0.6544\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.7719 - acc: 0.7443 - val_loss: 1.0707 - val_acc: 0.6483\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.7274 - acc: 0.7753 - val_loss: 1.1220 - val_acc: 0.6585\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.6751 - acc: 0.7887 - val_loss: 1.0745 - val_acc: 0.6483\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.6307 - acc: 0.8068 - val_loss: 1.1217 - val_acc: 0.6237\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.5887 - acc: 0.8402 - val_loss: 1.2395 - val_acc: 0.6892\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.5397 - acc: 0.8526 - val_loss: 1.0963 - val_acc: 0.6605\n",
      "Epoch 15/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.4462 - acc: 0.8980 - val_loss: 1.1199 - val_acc: 0.6728\n",
      "Epoch 16/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.3955 - acc: 0.9120 - val_loss: 1.2088 - val_acc: 0.6769\n",
      "Epoch 17/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.3855 - acc: 0.9100 - val_loss: 1.2802 - val_acc: 0.6789\n",
      "Epoch 18/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.3757 - acc: 0.9107 - val_loss: 1.2939 - val_acc: 0.6646\n",
      "Epoch 19/20\n",
      "4411/4411 [==============================] - 16s 4ms/step - loss: 0.3542 - acc: 0.9168 - val_loss: 1.2895 - val_acc: 0.6646\n",
      "Epoch 20/20\n",
      "4411/4411 [==============================] - 16s 4ms/step - loss: 0.3331 - acc: 0.9275 - val_loss: 1.4727 - val_acc: 0.6769\n",
      "Accuracy: 0.6768916155419223\n",
      "F1-score macro: 0.489236081752891\n",
      "F1-score micro: 0.6768916155419223\n",
      "F1-score weighted: 0.6364304056940973\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 20s 4ms/step - loss: 17.8321 - acc: 0.6017 - val_loss: 12.0264 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 8.8726 - acc: 0.6230 - val_loss: 5.7936 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 4.2979 - acc: 0.6189 - val_loss: 2.8729 - val_acc: 0.6237\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 2.2508 - acc: 0.5990 - val_loss: 1.6545 - val_acc: 0.6462\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.3615 - acc: 0.6253 - val_loss: 1.2036 - val_acc: 0.6401\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 11s 2ms/step - loss: 1.0109 - acc: 0.6667 - val_loss: 1.0812 - val_acc: 0.6155\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.8910 - acc: 0.6776 - val_loss: 1.0762 - val_acc: 0.6115\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.8187 - acc: 0.7112 - val_loss: 1.0755 - val_acc: 0.6196\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.7457 - acc: 0.7533 - val_loss: 1.0832 - val_acc: 0.6278\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.6709 - acc: 0.7989 - val_loss: 1.1378 - val_acc: 0.6115\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.6309 - acc: 0.8087 - val_loss: 1.1828 - val_acc: 0.5951\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.6053 - acc: 0.8250 - val_loss: 1.1887 - val_acc: 0.6155\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.5410 - acc: 0.8572 - val_loss: 1.1827 - val_acc: 0.5992\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.4828 - acc: 0.8819 - val_loss: 1.2434 - val_acc: 0.5746\n",
      "Accuracy: 0.6462167689161554\n",
      "F1-score macro: 0.30696316262353995\n",
      "F1-score micro: 0.6462167689161554\n",
      "F1-score weighted: 0.5400716940709996\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 18s 4ms/step - loss: 17.9280 - acc: 0.5797 - val_loss: 12.1022 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 8.9138 - acc: 0.6232 - val_loss: 5.8258 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 4.3313 - acc: 0.6205 - val_loss: 2.8790 - val_acc: 0.6237\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 2.2655 - acc: 0.5967 - val_loss: 1.6364 - val_acc: 0.6299\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 1.3859 - acc: 0.6178 - val_loss: 1.1559 - val_acc: 0.6278\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 1.0330 - acc: 0.6418 - val_loss: 0.9925 - val_acc: 0.6708\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.8920 - acc: 0.6586 - val_loss: 0.9693 - val_acc: 0.6585\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.8234 - acc: 0.6969 - val_loss: 0.9946 - val_acc: 0.6524\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.7785 - acc: 0.7270 - val_loss: 1.0127 - val_acc: 0.6564\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.7300 - acc: 0.7531 - val_loss: 1.0202 - val_acc: 0.6646\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.6837 - acc: 0.7824 - val_loss: 1.0504 - val_acc: 0.6810\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.6216 - acc: 0.8189 - val_loss: 1.1085 - val_acc: 0.6544\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.5992 - acc: 0.8259 - val_loss: 1.1445 - val_acc: 0.6524\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.5537 - acc: 0.8433 - val_loss: 1.1539 - val_acc: 0.6278\n",
      "Epoch 15/20\n",
      "4411/4411 [==============================] - 11s 3ms/step - loss: 0.5493 - acc: 0.8465 - val_loss: 1.1538 - val_acc: 0.6728\n",
      "Epoch 16/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.4874 - acc: 0.8801 - val_loss: 1.2857 - val_acc: 0.6748\n",
      "Epoch 17/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.4827 - acc: 0.8696 - val_loss: 1.1759 - val_acc: 0.6871\n",
      "Epoch 18/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.4018 - acc: 0.9080 - val_loss: 1.2469 - val_acc: 0.6953\n",
      "Epoch 19/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.3691 - acc: 0.9159 - val_loss: 1.3786 - val_acc: 0.6810\n",
      "Epoch 20/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.3766 - acc: 0.9143 - val_loss: 1.5106 - val_acc: 0.6789\n",
      "Accuracy: 0.6789366053169734\n",
      "F1-score macro: 0.4933606378869012\n",
      "F1-score micro: 0.6789366053169734\n",
      "F1-score weighted: 0.6348281435658749\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 17s 4ms/step - loss: 17.8605 - acc: 0.5765 - val_loss: 12.0577 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 8.8858 - acc: 0.6232 - val_loss: 5.8212 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 30s 7ms/step - loss: 4.3168 - acc: 0.6166 - val_loss: 2.8752 - val_acc: 0.6237\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 2.2600 - acc: 0.6008 - val_loss: 1.6335 - val_acc: 0.6442\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 1.3823 - acc: 0.6219 - val_loss: 1.1689 - val_acc: 0.6544\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 1.0264 - acc: 0.6450 - val_loss: 1.0157 - val_acc: 0.6769\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 12s 3ms/step - loss: 0.8749 - acc: 0.6819 - val_loss: 1.0212 - val_acc: 0.6544\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.8178 - acc: 0.7021 - val_loss: 1.0297 - val_acc: 0.6462\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.7392 - acc: 0.7481 - val_loss: 1.0495 - val_acc: 0.6462\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.6833 - acc: 0.7869 - val_loss: 1.1052 - val_acc: 0.6442\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.6331 - acc: 0.8084 - val_loss: 1.1881 - val_acc: 0.6585\n",
      "Epoch 12/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.6041 - acc: 0.8245 - val_loss: 1.1718 - val_acc: 0.6483\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.5472 - acc: 0.8497 - val_loss: 1.2651 - val_acc: 0.6217\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.5606 - acc: 0.8506 - val_loss: 1.2631 - val_acc: 0.6667\n",
      "Epoch 15/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.5222 - acc: 0.8619 - val_loss: 1.2638 - val_acc: 0.6748\n",
      "Epoch 16/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.4580 - acc: 0.8860 - val_loss: 1.2298 - val_acc: 0.6524\n",
      "Accuracy: 0.6768916155419223\n",
      "F1-score macro: 0.4196423803330993\n",
      "F1-score micro: 0.6768916155419223\n",
      "F1-score weighted: 0.6039917172350103\n",
      "========================================================\n",
      "Train on 4411 samples, validate on 489 samples\n",
      "Epoch 1/20\n",
      "4411/4411 [==============================] - 24s 5ms/step - loss: 17.7424 - acc: 0.5946 - val_loss: 11.9693 - val_acc: 0.6237\n",
      "Epoch 2/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 8.8130 - acc: 0.6230 - val_loss: 5.7691 - val_acc: 0.6237\n",
      "Epoch 3/20\n",
      "4411/4411 [==============================] - 17s 4ms/step - loss: 4.2722 - acc: 0.6017 - val_loss: 2.8523 - val_acc: 0.6258\n",
      "Epoch 4/20\n",
      "4411/4411 [==============================] - 20s 5ms/step - loss: 2.2242 - acc: 0.5994 - val_loss: 1.6330 - val_acc: 0.6564\n",
      "Epoch 5/20\n",
      "4411/4411 [==============================] - 19s 4ms/step - loss: 1.3488 - acc: 0.6547 - val_loss: 1.1860 - val_acc: 0.6380\n",
      "Epoch 6/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 1.0308 - acc: 0.6377 - val_loss: 1.0463 - val_acc: 0.6380\n",
      "Epoch 7/20\n",
      "4411/4411 [==============================] - 17s 4ms/step - loss: 0.8890 - acc: 0.6722 - val_loss: 1.0269 - val_acc: 0.6360\n",
      "Epoch 8/20\n",
      "4411/4411 [==============================] - 14s 3ms/step - loss: 0.8206 - acc: 0.7037 - val_loss: 1.0295 - val_acc: 0.6319\n",
      "Epoch 9/20\n",
      "4411/4411 [==============================] - 17s 4ms/step - loss: 0.7339 - acc: 0.7518 - val_loss: 1.0866 - val_acc: 0.6094\n",
      "Epoch 10/20\n",
      "4411/4411 [==============================] - 17s 4ms/step - loss: 0.6839 - acc: 0.7869 - val_loss: 1.1371 - val_acc: 0.6012\n",
      "Epoch 11/20\n",
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.6539 - acc: 0.8021 - val_loss: 1.1717 - val_acc: 0.6278\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4411/4411 [==============================] - 13s 3ms/step - loss: 0.5970 - acc: 0.8270 - val_loss: 1.1672 - val_acc: 0.6012\n",
      "Epoch 13/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.5413 - acc: 0.8538 - val_loss: 1.2509 - val_acc: 0.5828\n",
      "Epoch 14/20\n",
      "4411/4411 [==============================] - 15s 3ms/step - loss: 0.5212 - acc: 0.8549 - val_loss: 1.3599 - val_acc: 0.5542\n",
      "Accuracy: 0.656441717791411\n",
      "F1-score macro: 0.34457175717728716\n",
      "F1-score micro: 0.656441717791411\n",
      "F1-score weighted: 0.557404336481863\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state = 42, shuffle = True)\n",
    "skf.get_n_splits(X, y)\n",
    "y_new = np.argmax(y, axis = 1)\n",
    "\n",
    "eval_result = []\n",
    "for train_index, test_index in skf.split(X, y_new):\n",
    "    print('========================================================')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    accu, f1 = cnn_train(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    eval_result.append((accu,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6594085441783663\n",
      "0.4055663476660136\n"
     ]
    }
   ],
   "source": [
    "sum_acc = 0\n",
    "sum_f1 = 0\n",
    "for item in eval_result:\n",
    "    sum_acc += item[0]\n",
    "    sum_f1 += item[1]\n",
    "\n",
    "print(sum_acc/10)\n",
    "print(sum_f1/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
